## **ğŸ«€ NRC-Net: Noise-Robust Cardio Net for Heart Sound Classification**

### **ğŸ” Overview**
NRC-Net is a lightweight and efficient **Deep Learning model** designed to classify **heart sounds** and detect valvular cardiac diseases, even in the presence of **noisy environments**. This model utilizes **Continuous Wavelet Transform (CWT)** as the optimal transformation method and achieves an accuracy of **86%** on our trained dataset.

Inspired by the research paper **["NRC-Net: Automated Noise Robust Cardio Net for Detecting Valvular Cardiac Diseases"](https://doi.org/10.1016/j.bspc.2023.105272)**, we trained and fine-tuned NRC-Net on a heart sound dataset to improve real-world applicability in medical diagnostics.

---

## **ğŸ“Œ Features**
âœ… **Lightweight Model** - Optimized for efficiency while maintaining high accuracy.  
âœ… **Noise-Robust** - Can classify heart conditions despite ambient noise interference.  
âœ… **Deep Learning Powered** - Uses a combination of **Convolutional Neural Networks (CNN)** and **Recurrent Neural Networks (RNN)**.  
âœ… **Attention Mechanism** - Incorporates an **Attention Block** for better feature extraction.  
âœ… **Medical Applicability** - Can assist in early **Cardiovascular Disease (CVD)** detection, particularly in **low-resource settings**.

---

## **ğŸ“š Dataset**
We trained **NRC-Net** on a **Heart Sound Dataset** consisting of five heart sound categories:  
ğŸ”¹ **Mitral Regurgitation (MR)**  
ğŸ”¹ **Aortic Stenosis (AS)**  
ğŸ”¹ **Mitral Stenosis (MS)**  
ğŸ”¹ **Mitral Valve Prolapse (MVP)**  
ğŸ”¹ **Normal Heart Sounds (N)**  

### **Data Preprocessing**  
âœ” **Bandpass filtering** (50Hz - 800Hz)  
âœ” **Resampling** (2000Hz)  
âœ” **Noise Augmentation** (Lung sound & AWGN noise at various SNRs)  

---

## **ğŸ› ï¸ Model Architecture**
NRC-Net is built using a combination of **CNN & RNN** layers with attention-based feature extraction:

### **ğŸ¢ Architecture Components**
1ï¸âƒ£ **Spatial Feature Extractor Block (SFEB)** - Extracts spatial features using CNN layers.  
2ï¸âƒ£ **Holistic Attention Block (HAB)** - Highlights important features using channel-wise attention.  
3ï¸âƒ£ **Temporal Feature Extractor Block (TFEB)** - Captures sequential dependencies using LSTMs.  
4ï¸âƒ£ **Terminal Classification Block (TCB)** - Final dense layers for classification.  

---

## **ğŸš€ Performance**
ğŸ“Š **Accuracy**: **86%** (on our dataset)  
ğŸ“‰ **Robustness to Noise**: NRC-Net performs well even under **noisy heart sound conditions**.  
ğŸ† **Optimized for Deployment**: Lower computational overhead compared to traditional deep networks.  

---

## **ğŸ—‚ How to Run**
### **ğŸ–¥ï¸ Requirements**
```
Python 3.8+
TensorFlow / PyTorch
NumPy
Matplotlib
Librosa (for audio processing)
```

### **ğŸ”§ Installation**
```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/NRC-Net.git
cd NRC-Net
pip install -r requirements.txt
```

### **ğŸ“ Training the Model**
```python
python train.py --epochs 50 --batch_size 16
```

### **ğŸ” Running Inference**
```python
python predict.py --audio_path sample.wav
```

---

## **ğŸ“– Research Paper Credit**
This project is heavily inspired by:  
ğŸ“ **["NRC-Net: Automated Noise Robust Cardio Net for Detecting Valvular Cardiac Diseases"](https://doi.org/10.1016/j.bspc.2023.105272)**  
Published in *Biomedical Signal Processing and Control (2023)*.

We acknowledge the authors for their research and methodologies, which helped in shaping this project.

---

## **ğŸ”® Future Improvements**
ğŸ”¹ **Enhancing Model Accuracy** - Fine-tuning NRC-Net for even higher classification accuracy.  
ğŸ”¹ **Deploying in Medical Applications** - Integration with real-world **digital stethoscopes**.  
ğŸ”¹ **Explainability with GradCAM** - Improving interpretability for **medical professionals**.  
ğŸ”¹ **Handling More Noise Sources** - Adding robustness to **hospital ambient noises**.  

---

## **ğŸ‘¨â€ğŸ’» Contributors**
ğŸ’¡ **Mehul Mridul** - Core Developer  
ğŸ’¡ **Ahhsan Hoque**  
ğŸ’¡ **Saatvik Krishna Vaish**  

---

## **ğŸ—ƒï¸ License**
This project is licensed under the **MIT License**.


